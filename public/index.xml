<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Cornell RPAL</title>
    <link>https://rpal.cs.cornell.edu/</link>
    <description>Recent content on Cornell RPAL</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 11 Apr 2017 17:25:09 -0500</lastBuildDate>
    
	<atom:link href="https://rpal.cs.cornell.edu/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Ph.D. Student Wil Thomason Receives NSF GRFP and NDSEG Fellowship</title>
      <link>https://rpal.cs.cornell.edu/news/thomason_grfp/</link>
      <pubDate>Tue, 11 Apr 2017 17:25:09 -0500</pubDate>
      
      <guid>https://rpal.cs.cornell.edu/news/thomason_grfp/</guid>
      <description>Second-year Ph.D. student Wil Thomason was awarded a four-year fellowship through the National Defense Science and Engineering Graduate Fellowship. He also received a three-year fellowship through the National Science Foundation&amp;rsquo;s Graduate Research Fellowship Program.</description>
    </item>
    
    <item>
      <title>Claire Liang</title>
      <link>https://rpal.cs.cornell.edu/people/claire/</link>
      <pubDate>Tue, 07 Mar 2017 17:50:12 -0500</pubDate>
      
      <guid>https://rpal.cs.cornell.edu/people/claire/</guid>
      <description>Claire is a Senior in Computer Science working on the Hanabi Implicature Project. In this work she is developing a game AI that she believes matches human intuition&amp;rsquo;s use of implicature and is exploring the impact of quantity of presented information in the game&amp;rsquo;s user interface. She has previously worked on stem cell population simulation including spatial modeling, and protein crystallizability prediction. Her current interests lie in mathematics - specifically geometry and topology - and its use in a broad range of real world modeling questions.</description>
    </item>
    
    <item>
      <title>Paper Nominated for Best Paper Award at HRI 2017</title>
      <link>https://rpal.cs.cornell.edu/news/hri2017_nominated_best_paper/</link>
      <pubDate>Tue, 07 Mar 2017 17:25:09 -0500</pubDate>
      
      <guid>https://rpal.cs.cornell.edu/news/hri2017_nominated_best_paper/</guid>
      <description>The paper &amp;ldquo;Implicit Communication in a Joint Action&amp;rdquo;, by Ross Knepper, Christoforos Mavrogiannis, Julia Proft, and Claire Liang, has been nominated for a Best Paper Award at HRI 2017.
For more on the paper, please see the announcement of its acceptance.</description>
    </item>
    
    <item>
      <title>Zach Zweig Vinegar</title>
      <link>https://rpal.cs.cornell.edu/people/zach/</link>
      <pubDate>Tue, 07 Feb 2017 05:56:51 -0500</pubDate>
      
      <guid>https://rpal.cs.cornell.edu/people/zach/</guid>
      <description>I am a senior computer science major in the College of Engineering at Cornell University. My current research interests lie in the areas of human-robot interaction, computer vision, and augmented reality. I am also a member of Cornell&amp;rsquo;s Robotic Personal Assistants Lab run by Prof. Ross Knepper. Currently, I am working on a telepresence robot equipped with a 360 degree RGB-D sensor. The goal is to use the data coming from the sensor to enable the robot to seamlessly and smoothly navigate crowded pedestrian environments.</description>
    </item>
    
    <item>
      <title>Valts Blukis</title>
      <link>https://rpal.cs.cornell.edu/people/valts/</link>
      <pubDate>Mon, 06 Feb 2017 09:58:51 -0500</pubDate>
      
      <guid>https://rpal.cs.cornell.edu/people/valts/</guid>
      <description>Valts is a first-year PhD student in computer science. He graduated with a degree in Electrical and Electronic Engineering from Nanyang Technological University in Singapore. In the past he has worked on rescue robotics and stereo vision. He is interested in robotics and machine learning, in particular developing algorithms that would improve robot understanding of the real world and allow competent interactions with people.</description>
    </item>
    
    <item>
      <title>Social Navigation</title>
      <link>https://rpal.cs.cornell.edu/projects/social_nav/</link>
      <pubDate>Wed, 25 Jan 2017 20:09:33 -0500</pubDate>
      
      <guid>https://rpal.cs.cornell.edu/projects/social_nav/</guid>
      <description>Despite the great progress in the field of robotic navigation over the past few decades, navigating a human environment remains a hard task for a robot, due to the lack of formal rules guiding traffic, the lack of explicit communication among agents and the unpredictability of human behavior. Existing approaches often result in robot motion that is hard to read, which causes unpredictable human reactions to which the robot in turn reacts to, contributing to an oscillatory joint behavior that hinders humans’ paths.</description>
    </item>
    
    <item>
      <title>Situated Gesture and Speech</title>
      <link>https://rpal.cs.cornell.edu/data/gestures/</link>
      <pubDate>Wed, 25 Jan 2017 20:09:23 -0500</pubDate>
      
      <guid>https://rpal.cs.cornell.edu/data/gestures/</guid>
      <description>As a part of our work on unfamiliar gesture recognition, we encountered a need for a large, high-quality dataset of situated gesture and speech &amp;mdash; gestures and speech used at the same time by the same person to describe the same things. Such a dataset is central to our approach to zero-shot learning for gesture understanding (Thomason and Knepper, 2016). As we were unable to find a large dataset of this type, we collected this dataset during 2016 and 2017.</description>
    </item>
    
    <item>
      <title>Unfamiliar Gestures</title>
      <link>https://rpal.cs.cornell.edu/projects/gestures/</link>
      <pubDate>Wed, 25 Jan 2017 20:09:23 -0500</pubDate>
      
      <guid>https://rpal.cs.cornell.edu/projects/gestures/</guid>
      <description>Human communication is highly multimodal, including speech, gesture, gaze, facial expressions, and body language. Robots serving as human teammates must act on such multimodal communicative inputs from humans, even when the message may not be clear from any single modality. In this paper, we explore a method for achieving increased understanding of complex, situated communications by leveraging coordinated natural language, gesture, and context.
Our work departs from the traditional model of gesture recognition in that the set of gestures it can recognize is not limited to the gestural lexicon used for its training.</description>
    </item>
    
    <item>
      <title>Solar Airship</title>
      <link>https://rpal.cs.cornell.edu/projects/blimp/</link>
      <pubDate>Wed, 25 Jan 2017 20:09:13 -0500</pubDate>
      
      <guid>https://rpal.cs.cornell.edu/projects/blimp/</guid>
      <description>Primary objectives are to (1) build a control system that enables persistent autonomy. (2) Develop a power system that is capable of operating the blimp and processing hardware using attached solar panels. (3) Develop computer vision algorithms to support research efforts, scientific observations of natural phenomena, and path planning activity. A sensor package will be designed with collaborators at the International Livestock Research Institute in Kenya for prediction of drought. Other future applications include surveillance of remote territory and disaster monitoring.</description>
    </item>
    
    <item>
      <title>Ross Knepper</title>
      <link>https://rpal.cs.cornell.edu/people/ross/</link>
      <pubDate>Wed, 25 Jan 2017 16:12:51 -0500</pubDate>
      
      <guid>https://rpal.cs.cornell.edu/people/ross/</guid>
      <description>Ross A. Knepper is an Assistant Professor in the Department of Computer Science at Cornell University. His research focuses on the theory, algorithms, and mechanisms of automated assembly and human-robot collaboration. Previously, Ross was a Research Scientist in the Distributed Robotics Lab at MIT. Ross received his M.S and Ph.D. degrees in Robotics from Carnegie Mellon University in 2007 and 2011. Before his graduate education, Ross worked in industry at Compaq, where he designed high-performance algorithms for scalable multiprocessor systems; and also in commercialization at the National Robotics Engineering Center, where he adapted robotics technologies for customers in government and industry.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://rpal.cs.cornell.edu/about/</link>
      <pubDate>Wed, 25 Jan 2017 00:25:59 -0500</pubDate>
      
      <guid>https://rpal.cs.cornell.edu/about/</guid>
      <description>The Robotic Personal Assistants Lab is focused on advancing the state of the art in human-robot interaction, robotic manipulation, automated assembly, and multi-agent planning and coordination. We work on projects fusing theoretical advances with empirically assessed implementations.</description>
    </item>
    
    <item>
      <title>Contact Information</title>
      <link>https://rpal.cs.cornell.edu/contact/</link>
      <pubDate>Wed, 25 Jan 2017 00:25:51 -0500</pubDate>
      
      <guid>https://rpal.cs.cornell.edu/contact/</guid>
      <description>Contact us via email at rpal@cs.{our&amp;nbsp;university}.edu </description>
    </item>
    
    <item>
      <title>Paper Accepted to HRI 2017</title>
      <link>https://rpal.cs.cornell.edu/news/hri2017/</link>
      <pubDate>Tue, 24 Jan 2017 23:47:43 -0500</pubDate>
      
      <guid>https://rpal.cs.cornell.edu/news/hri2017/</guid>
      <description>The paper &amp;ldquo;Implicit Communication in a Joint Action&amp;rdquo;, by Ross Knepper, Christoforos Mavrogiannis, Julia Proft, and Claire Liang, has been accepted to HRI 2017.
From the paper:
 Actions performed in the context of a joint activity comprise two aspects: functional and communicative. The functional component achieves the goal of the action, whereas its communicative component, when present, expresses some information to the actor’s partners in the joint activity. The interpretation of such communication requires leveraging information that is public to all participants, known as common ground.</description>
    </item>
    
    <item>
      <title>Paper Presented at WAFR 2016</title>
      <link>https://rpal.cs.cornell.edu/news/wafr2016/</link>
      <pubDate>Tue, 20 Dec 2016 23:47:43 -0500</pubDate>
      
      <guid>https://rpal.cs.cornell.edu/news/wafr2016/</guid>
      <description>The paper &amp;ldquo;Decentralized Multi-Agent Navigation Planning with Braids&amp;rdquo;, by Christoforos Mavrogiannis and Ross Knepper, was presented at WAFR 2016.
From the paper:
 We present a novel planning framework for navigation in dynamic, multi-agent environments with no explicit communication among agents, such as pedestrian scenes. Inspired by the collaborative nature of human navigation, our approach treats the problem as a coordination game, in which players coordinate to avoid each other as they move towards their destinations.</description>
    </item>
    
    <item>
      <title>Daryl Sew</title>
      <link>https://rpal.cs.cornell.edu/people/daryl/</link>
      <pubDate>Wed, 26 Oct 2016 21:19:59 -0500</pubDate>
      
      <guid>https://rpal.cs.cornell.edu/people/daryl/</guid>
      <description>Computer Science undergraduate interested in computer vision, machine learning and robotics.</description>
    </item>
    
    <item>
      <title>Julia Proft</title>
      <link>https://rpal.cs.cornell.edu/people/julia/</link>
      <pubDate>Sun, 21 Aug 2016 00:00:00 -0500</pubDate>
      
      <guid>https://rpal.cs.cornell.edu/people/julia/</guid>
      <description>Julia is a first-year PhD student in computer science. Her research interests are in robotics and human-robot interaction, in particular developing shared-control algorithms that make robots easier to teleoperate and leverage the complementary strengths of the human operator and the robot. She also works part-time for the Anita Borg Institute, a non-profit organization dedicated to connecting, supporting, and inspiring women in technology.</description>
    </item>
    
    <item>
      <title>Vitchyr Pong</title>
      <link>https://rpal.cs.cornell.edu/people/vitchyr/</link>
      <pubDate>Tue, 26 Jan 2016 21:20:10 -0500</pubDate>
      
      <guid>https://rpal.cs.cornell.edu/people/vitchyr/</guid>
      <description>Undergraduate in ECE and CS, moved on to a PhD at UC Berkeley.</description>
    </item>
    
    <item>
      <title>Alex Volkov</title>
      <link>https://rpal.cs.cornell.edu/people/alex/</link>
      <pubDate>Tue, 26 Jan 2016 21:19:52 -0500</pubDate>
      
      <guid>https://rpal.cs.cornell.edu/people/alex/</guid>
      <description>ECE undergraduate, moved on to a Master&amp;rsquo;s at the CMU Robotics Institute.</description>
    </item>
    
    <item>
      <title>Wil Thomason</title>
      <link>https://rpal.cs.cornell.edu/people/wil/</link>
      <pubDate>Sun, 25 Jan 2015 16:12:51 -0500</pubDate>
      
      <guid>https://rpal.cs.cornell.edu/people/wil/</guid>
      <description>Wil is a second-year PhD student in computer science. He is interested in a broad range of topics in robotics and CS, including multi-agent planning, human-robot interaction (with a particular focus on language and gesture understanding), and machine learning for robotics.</description>
    </item>
    
    <item>
      <title>Minae Kwon</title>
      <link>https://rpal.cs.cornell.edu/people/minae/</link>
      <pubDate>Sun, 26 Jan 2014 21:20:05 -0500</pubDate>
      
      <guid>https://rpal.cs.cornell.edu/people/minae/</guid>
      <description>I’m interested in facilitating collaboration between robots and humans by computationally expressing findings from social and cognitive psychology to model human behavior and appropriately design robot behavior. Currently, I am working on how humans form expectations of social robots and how we can help people form more accurate mental models of them. When not doing research, I enjoy debating (competitively), watching movies, and traveling.</description>
    </item>
    
    <item>
      <title>Christoforos Mavrogiannis</title>
      <link>https://rpal.cs.cornell.edu/people/chris/</link>
      <pubDate>Sat, 25 Jan 2014 15:50:27 -0500</pubDate>
      
      <guid>https://rpal.cs.cornell.edu/people/chris/</guid>
      <description>Christoforos received a Diploma in Mechanical Engineering from the National Technical University of Athens, Greece in 2013. He is currently a PhD candidate in the Sibley School of Mechanical and Aerospace Engineering. His PhD research is focused on the design of navigation planning algorithms for robots operating in crowded environments. Inspired by insights from cognitive science and psychology, he employs tools from topology, motion planning and machine learning to address the problem of generating socially competent robot behaviors in pedestrian environments.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://rpal.cs.cornell.edu/projects/blimp/splash/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://rpal.cs.cornell.edu/projects/blimp/splash/</guid>
      <description>Who We Are: We are a project team working to build an autonomous blimp capable of long-term independent flight. Our team is primarily student run under the advisement of Professor Ross Knepper. The team is organized into 3 primary sub-teams: hardware, simulation, and software. Areas of interest are high-level motion planning, circuit design, sensor fusion, dynamics modeling, power system design, and computer vision.
What We’re Looking For: At this time we’re looking for students of all levels with interest and experience in any of the following areas:</description>
    </item>
    
  </channel>
</rss>